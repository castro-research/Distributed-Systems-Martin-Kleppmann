# Two Generals Problems

hello everybody welcome back in the last lecture we introduced distributed systems by looking at some concrete examples such as the web and rpc which are examples of client server systems in this lecture we're going to move things to a little bit more abstract and a little bit more general model and we're going to talk about system models for distributed systems which are uh descriptions of the assumptions that we make when we're designing an algorithm to run in a distributed systems so a system model is very important because as we discussed things can go wrong in the distributed systems nodes can crash networks can fail and so on and we have to be precise about what failures we are assuming are possible and what failures we are assuming are not possible so we're going to start this by looking at two classic thought experiments from distributed systems the two generals problem and the byzantine generals problem and we're going to start now with the two generals problem so uh this is it's kind of like a military analogy so i'm sorry about that i'm not really a big fan of that but it's widely known as the two generals problems so i'm just going to stick with the convention here and so the setting of this thought experiment is that we have two armies each army is controlled by one general and these armies are wanting to attack and capture a city now the city is well defended and so if only one of the armies attacks at one time that army will get defeated and so it's very important that if the two generals are going to attack they attack at the same time because then if both the armies attack at the same time they know that they are going to win so you can see from this truth table here what happens is okay it's it's all right if neither of the two armies attacks but if only one of the two armies attacks then it it's all going to go terribly wrong so what we really want is that one army attacks if and only if the other army attacks so both are attack together now what makes this difficult is that the two generals can't just talk to each other and agree on their plan of when to attack but they can only communicate via messengers and so these messengers there are people who run with the messengers through the forest and as they run through the forest they might get captured by by forces of the city and so whenever an ah whenever one of the general sends a messenger to the other general that message may or may not get through and there's no way for the sender of the message to know whether the message got through except by receiving a response and so the problem here is now this so imagine for example general one has decided to attack on the 10th of november and so he sends a message to general two uh saying we're going to attack on the 10th november are you okay with that and general 2 receives the message and says yes i'm on board we're going to attack together on the 10th of november sends that response back but unfortunately the response message is captured so the initial message the request get through but the response is lost and so now general one does not receive a response now this uh this is one scenario of what could happen here's another scenario of what could happen it could also happen that general one sends the message attack on the 10th of november to general two but that initial message is lost and never gets through to general two and now general two doesn't receive any message so he's not going to respond either and the end result is also the general one does not receive a response so in both of these two cases the only thing that general one observes is no response but general one does not know whether there's no response because the initial message didn't get through or whether the response was lost but there's a big difference between the two of these because from general two's point of view in the first case general two has agreed to attack in the second case general two doesn't even know about the attack so they look the same from general two's point of view but they look very different from general sorry they look the same from general one's point of view but they look very different from general two's point of view so let's try to design an algorithm which will nevertheless get the two generals into agreement and so let's think about it first of all from the point of view of general one general one basically has two choices either general one is going to always attack no matter whether any response is received or general one is going to wait and only attack if it receives a response from general two so let's start with the first case so uh general one always attacks even if no response is received so in this case uh general one wants to make sure that general two is also going to attack because also because otherwise general one is going to be in a problem problematic situation so we could say that general one is going to send lots and lots and lots of messengers over to general two all saying attack at this time attack attack and if one of those gets through then things are probably okay because general two knows that general one is always going to attack so general two knows that it's safe for uh general two to also go into battle uh even without responding to general one because after all general one has promised that um that that general one is always going to attack however it could happen that all of the messengers are lost and so in this case general two does not know about the attack so general one ends up going into battle alone and loses so that means this first option of general one always attacking is not really great so let's consider the alternative which is that general one does not promise to always attack but general one will only attack if it receives a positive response from general two and in this case general one is safe because general one knows that it will only go into battle if general two uh is going into battle but now if you think about it from general two's point of view now general two uh knows that the um that general one will only go into attack if the response from general two to general one gets through because after all general one is waiting for that response from number two and so now the general two is in exactly the same situation as general one was in the first option and that is either general two must commit to always attack in which case he risks being alone in the battle or general two will wait for a response from general one but now you know general one has to reply and so you end up with these potentially infinite chains of yes yes i'm going to attack okay i'm going to attack if you attack yes okay i will attack but only if you also attack yes yes already said i'm going to attack and so on and so they have to send each other back and forth these messages you get actually an infinite chain before there's any certainty that they're actually both going to attack together and so what is this is called in distributed systems the problem of having no common knowledge so there's no knowledge in the system that one node knows and the other node knows that the first node knows it and the sec the first node knows that the second node knows that the first node knows it and so on so you can construct these arbitrary chains and the end result is just that no matter how many finite sequences of messages we send back and forth we never actually have absolute certainty that general one is going to attack if and only if general two is going to attack so you can build up gradually increasing uh like probabilistic certainty maybe depending on your assumptions of whether messengers get captured or not but it's actually impossible to reach complete certainty here now let's take this abstract thought experiment and apply it to a concrete example so we had in the last lecture this example of an online shop making an rpc request to a payment service in order to charge a credit card and really what we want here is that the online shop dispatches the goods if and only if the customer pays for the goods because you can imagine you know if the online shop dispatches the goods but the payment service does not charge the credit card then the shop is unhappy because the shop has just given away some goods for free if the uh if the online shop does not dispatch the goods but the payment service does charge the credit card then the customer is unhappy because the customer got charged without receiving any goods so really what we want is something that looks extremely similar to the two generals problem here that the online shop dispatches to goods if and only if the payment service charges the card and as you can imagine the rpc between the online shop and the payment service looks very much like the messengers running through the forest in the two generals problem which is to say that the messages might get lost either one or the other might get lost and so it is actually not possible for the online shop and the payment service to achieve the certainty that one action will happen if and only if the other other action happens now in practice actually of course online shops do work but the reason they work is because there are a bunch of second level safeguards then which uh ensure a reasonable outcome so for example if it turns out that the paint the card got charged but the online shop doesn't actually have the goods in stock anymore then the online shop will just send an apology email saying oh sorry actually we're out of stock we've refunded your card and so that way it's fine and so this it's possible to get out of this situation because the the charge is actually a revocable action it's possible to refund the charge and therefore it's back it's possible to get back into into a safe state where neither the goods dispatch nor the payment has effectively happened or another option is you know that the the payment service may or may not have charged a card and so the online shop then when the network is is repaired and the messenger's messages can get through again then the online shop checks with the payment service saying now did you actually charge that card or not because i never heard back from you whether you charge it or not and so what will probably happen is that the payment service will always go ahead and charge the card um because even if uh it's not certain that the online shop is going to dispatch the goods because uh in this case it's fine because the payment could get refunded if necessary so that is the way in which this online shopping problem is not actually exactly the same as the two generals problem but nevertheless the two generals problem does illustrate this issue of uh uncertainty that we have in a distributed system when we're not sure if the messages got through or not


the second thought experiment that i want to discuss is called the byzantine generals problem before i get into the details a question of pronunciation is it byzantine or byzantine generals well so as far as i know the standard british pronunciation of this word is actually byzantine and byzantine is the american pronunciation however in computing it seems to be most common to use byzantine and so i'm just going to stick with the pronunciation byzantine because that's what everyone else in computing seems to do so the byzantine generals problem is similar at first glance to the two generals problem that is again we've got generals leading armies again the armies want to attack a city in this case we might have three or more armies we might have any number of armies as before the generals communicate by messenger and as before we want the the armies want to agree on uh the date of attack so that to ensure that they attack at the same time now we make the problem easier in one way and harder in another way so easier first of all is we assume that messaging is reliable so in this case we're going to assume messengers don't get captured but any message that gets sent will actually be received by the appropriate recipient to make the problem harder we are now going to assume that some of the generals are actually not loyal they are traitors they are malicious they are going to try to actively undermine the other generals so they are going to lie and deceive and generally misbehave in any sort of way as they wish they might even work together and and nevertheless we want the honest generals to come to an agreement about the attack of the city so let me give an example of the problem that might arise due to some generals being malicious so here in this example general one sends a message to attack to generals two and three the same message attack and general three receives that message as expected general two receives the attack message and then sends a message to general three saying retreat so what general tu here is doing is lying general two claims that general one sent a retreat message when in fact general general one sent an attack message so in this case your general two is the one who is being malicious unfortunately from the point of general three it's not easy to tell what is actually happening because from the point of general three what could have just this equally well happened is this one so it could be that general one sent an attack message to three and general one sent a retreat message to 2 and general 2 is actually faithfully repeating that retreat message that it got from general 1. so in this case in the lower case here general 2 is being honest because general 2 is just reporting honestly what general one said and it's general one who is being malicious uh by sending contradictory commands to generals two and three so this is the the core of the problem here from the point of view of general three it's impossible to tell the difference between these two scenarios and so it's impossible for general three to tell whether general one is being malicious or whether general two is now given this scenario where where nodes might lie the byzantine general's problem is as i said the desire that is the problem is that we want all of the honest generals to come to an agreement so now the problem is that the honest generals don't know who the malicious generals are but we are going to assume some maximum number of generals being malicious so let's say that up to f generals are malicious out of n generals in total um the honest generals don't know who the malicious ones are but the malicious generals may know who the other militias generals are and so they might actually even work together in some coordinated fashion to try to deceive and trick the honest generals and nevertheless our requirement is that the honest generals agree on a plan so we can't claim we can't get the malicious generals to agree on any part of the plan because we're assuming that they might misbehave in arbitrary ways and so it's impossible for us to make any statement about what they are going to do but we can make a statement about what the honest generals are going to do and that is they will what we want them to do is to all attack on the same day now there are several different variants of the byzantine generals problem that vary in the details of how exactly it's set up but a typical result that we can prove about some of these variants is that if we have a maximum of f malicious generals then we need three f plus one at least three f plus one generals in total in order to tolerate those f uh generals being malicious that is less than one-third of the total number of generals can be malicious so if we have three generals and one is malicious the problem is unsolvable in order to tolerate a system with with one malicious general we need at least four that is f equals one uh we need at least four generals in total so three honest ones and one militias uh if we want a system which two generals might be malicious we actually need seven so five honest and two malicious generals now the problem becomes somewhat easier if we assume that we can use cryptography and so i won't go into the details of that in this course there's more detail on this in the security course and in the cryptography course that you will have next year and but what we can do here is use something called a digital signature which is a form of message in which it can be proved that a certain party sent a certain message and so in this case for example it would allow general 2 to prove what a command general 1 sent to general 2 and prove that to general three in a way that general three would be convinced um that general two really is honest so cryptography does help but it doesn't make the problem representing general problems magically simple so even if we do assume that we can use cryptography the problem remains difficult so is this at all of practical relevance you might ask so let's adapt this earlier example that we've had a few times now of the online shop and the payment service and let's take in this case the customer as a third party in this so we have this kind of three-way relationship between the shop the payment service and the customer and we want all three of these parties to agree on the status of a transaction or status of an order so we want the online shop to ship the the goods only if it agrees with the payment service that the payment actually happened and if the customer actually agreed that they did actually order this thing and the customer agrees on the quant on the amount that was charged the card and so on so all of these parties need to agree and in real life the trust relationships between these three parties might be quite complicated so if you think about it from the perspective of the online shop if there was some way how people could order goods from an online shop without paying for them you can imagine that fraudsters would be using that pretty quickly and they would be ordering all sorts of expensive things without paying for them and so the online shop would not be happy then so from the point of view of the online shop the customer needs to be treated as potentially malicious because if the customer was just blindly trusted then they might start doing fraudulent activity like that and so in that case we do have this kind of untrusting relationship uh what about the online shop and the payment service the relationship well you can imagine maybe the payment service doesn't quite trust the online shop because otherwise someone might set up a fraudulent online shop uh use say stolen credit card numbers to try and process transactions and get money um without actually shipping any real goods so in that case probably the online shop doesn't sorry the payment service doesn't fully trust the online shop but maybe the shop does trust the payment service so it might be this kind of asymmetric relationship so as you can see here the trust relationships in real life get rather complicated you do end up in these situations where one party does not trust another party and they nevertheless want to get something done and so in that sense byzantine behavior is real and practical the byzantine general's problem is of course a simplification of this kind of scenario because it's treating all of the generals as symmetric for example but nevertheless the byzantine generals problem is a useful starting point for studying these kind of situations in which the participants don't fully trust each other so before i wrap up about the byzantine generals problem one more little historical digression you might be wondering where the name byzantine comes from so this comes from the byzantine empire which also known as byzantium the former east roman empire which after the collapse of of the roman empire this was the the eastern part of it and its capital city was constantinople which was formerly known as byzantium uh which is now where istanbul is uh located in in turkey and so for some reason in the 20th century early 20th century i think the term byzantine became used in order to describe scenarios where things are excessively complicated or incredibly bureaucratic or potentially even devious uh for example tax legislation or these kind of thing not entirely sure why that um that meaning of byzantine occurred because there's no historical evidence really that the byzantine empire was any more or less malicious than any other empire but anyway that's where it came from so the the term byzantine had this meaning long before it was used in the context of computing so it outside of computing it has had that meaning for a long time so that's all on the byzantine general's problem for now

we've now seen the two generals problem and the byzantine general's problem in the two generals problem we assume that nodes are honest but messages might get lost in the byzantine general problem we assumed that messages are reliable but nodes might be dishonest so now well we should put the two together really and uh try and design system models for system in which both nodes and networks might go wrong in various ways and so this is really the foundation of any algorithms in distributed systems we need to assume certain things about what properties the system is going to have and typically we do that by looking at three different areas of interest so first of all we need to describe how we assume the network is going to behave secondly we're going to assume how nodes are going to behave and thirdly we need to assume how the timing and the system is going to work so the timing affects both networks and nodes so those are the three uh aspects of a system model that we're going to look at now in this section let's start with networks so i've repeated over and over again that networks are unreliable but just to re-emphasize that there are many reasons why message might get lost in a network some of them are just temporary overload a buffer gets full and so a message gets dropped but also there's some more fundamental problems even if you design it carefully so that your buffers never overflow some human operating a system might just unplug the wrong network cable and that means the network will be interrupted for the time that this network cable is unplugged no way around it there are also various other curious interactions which nate with nature that happen so google was observing for example on their subsea fiber optic cables that they were strange uh dam they observed strange damage on on these cables and they installed some underwater cameras and actually managed to observe sharks uh biting into their cables you can see the video at the link here on the slide do watch it it's incredibly cute um on land people have observed problems with cows stepping on fiber optic cables so a fiber optic cable was supposed to run along a power line but ended up trailing on the ground cal steps on it and the cowl makes enough of a kink in the cable that the light can't get through the the kink in the fiber optic cable and thus the network link gets interrupted this stuff really happens honestly so lots of reasons why networks might fail let's take this to a bit more abstract level so that we can reason about it in in a more formal way so typically in distributed systems and when we're designing distributed algorithms we are going to assume some kind of point-to-point communication so we're going to assume that messages have one sender and one recipient and they are sent over a bi-directional link so that the the recipient can then reply back to the sender so that's everything the type of link we've been talking about so far and we can then choose how we how reliable we are going to assume this link is and so the simplest model to program against is if we simply assume that the link is reliable and that is that messages always get through if a message is sent then it is received and if a message is received then it is sent than it was previously sent so the link doesn't lose messages and the link also doesn't fabricate messages out of thin air so a message is only received if it was sent but we're going to assume that messages can be reordered and so that is quite a strong assumption of course because links may not actually be this reliable in practice but we'll get to that in a moment the second assumption we could make with about network links is what is called a fair loss link so a fair loss link is one in which whenever you send a message it has a non-zero probability of being delivered so when you send a message it might get through it might not get through but if you keep repeating the sending of that message then we're going to assume that eventually it will get through we're not going to make any assumptions about how long that might take so it might take a long time until the message does finally get through but we're going to assume that if you assume an infinitely long execution time there will at some point within a finite amount of time be a point when every message is delivered and the third the weakest assumption we could make about network links is arbitrary so the network link is allowed to do anything we can model this in terms of a malicious active adversary who modifies the network traffic and so this actually does happen on the on the real internet if you're connecting to a coffee shop wi-fi the owner of that wi-fi could be interfering with your network packets in arbitrary ways and that means they might not just be looking at your network communication and like eavesdropping on it but they might actually modify the packets they might they might record packets and then replay them at some later point of time they might pretend to be some website and spoof it and of course they might drop messages as well and so an arbitrary link is allowed to do any of these things and um and unfortunately this is actually a reasonable model of how the internet works today now a final piece of terminology that i want to introduce here is the concept of a network partition so network partition is just if you have some nodes where the nodes are still continuing to run fine but the communication link between them is interrupted usually we talk about this interruption of being for some finite period of time so eventually the network partition does get repaired and at some point in the future they will be able to communicate again but the period of interruption might be quite substantial and this is an important thing to keep in mind so you might have systems for example where one subgroup of nodes is able to communicate a different subgroup of nodes is able to communicate but those two groups cannot communicate between them because the network link between the two groups is interrupted so this could absolutely happen so now the interesting thing with the three models of network behavior is that it's actually almost possible to convert one model into another so in particular if we have a fair loss link we can turn a fair loss link into a reliable link and the way we can do that is we simply keep retrying messages until they get through and on the recipient side that means we might get duplicate messages so we have to also deduplicate the messages on the recipient side and because with a fair loss link we are assuming that if we keep retrying a message will eventually get through then it is actually possible to turn this into a reliable link because we're assuming it will eventually get through and therefore by keep retrying it will eventually get through of course we're not saying anything about how long that is going to take it could potentially take a very long time for a message to get through but it will eventually get through interestingly it's all also almost possible to convert an arbitrary link into a fair loss link and the way we can do that is by using a cryptographic protocol such as tls. 

So tls, which stands for transport layer security is what gives you the little green padlock in the browser it's what gives you the s in https so it's a security protocol that allows typically a client and a server to communicate in a way that is resilient to people interfering with the network traffic so even if there's some active adversary on the network who is manipulating your network communication the tls protocol is able to guarantee that if the communication is successful then it hasn't been tampered with and it is authentic communication it hasn't been spoofed you don't have some some other person impersonating the website you're trying to communicate with and so on and the communication is private because it's encrypted and so by using a protocol like tls we're actually able to almost change an arbitrary link into a fair loss link.

The only thing we cannot do is if the active adversary just decides to block all communication ever in that case of course nothing is going to get through and you can't turn that into a fair loss link because we can't make any guarantee that eventually a message will get through if you keep retrying. 

But if we're willing to assume that the adversary will only interfere uh say with a finite number of packets then we could say that okay, the arbitrary link can be actually upgraded to a fair loss link and from there through retrying and deduplication we can actually turn it into a reliable link

So, that's our model of network behavior the next part of the system model is how the nodes behave 

so, of course nodes might fail in various ways as well and the first type of fault that we want to consider here is a crash fault and so in the crash stop abstraction for a process what this means is that we assume that a process might crash at any moment and once a process has crashed then it will never come back again it's just dead forever

So this is a simplifying assumption of course that it's going to be dead forever in some cases this is accurate so if you if your node is your phone and you drop your phone in the toilet, and the phone is there after broken you know the phone has suddenly disappeared off the face of the earth and it's never going to come back again, it's never going to be able to communicate again so therefore this you can model this as a crash stop failure, so the crash might not just be a software crash it could also be a catastrophic hardware failure where a node is simply destroyed and it will never be able to come back again. 

But in other systems we might want to assume actually that nodes might crash and then come back again they might recover after some period of time when a node crashes we probably want to assume that any in-memory state that it had is lost so any state that is not written to disk or to other some non-volatile storage will be lost um but any any data that is stored in in stable storage is able to survive the crash and will still be there after the node recovers of course a crash recovery model nodes might still crash and never come back again so that's still a possibility we're just adding the additional possibility that the node might recover after our crash and the third model of nodes is byzantine so exactly as in the as in the byzantine generals problem uh what it means for a node to be byzantine faulty is just it deviates from the algorithm so we specify an algorithm that all of the nodes are supposed to follow but a byzantine faulty node may not follow the algorithm it might pretend to follow the algorithm it might be it might do stuff to try and make it look honest even though it's actually behaving in some malicious way so we're not going to constrain the behavior of a byzantine faulty node in any way we're just going to assume that it can do anything that it wants uh including malicious behavior and so a piece of terminology here is we can always categorize a node as either faulty or correct um so a node is faulty if it crashes for example or in the byzantine model faulty is a node is 40 if it deviates from the algorithm a node is correct if it's not faulty so those are the two possibilities now we don't necessarily the one node does not necessarily know whether another node is correct or faulty and we will come to the problem of fault detection in a little while so we've talked about models for network models for nodes the third part is models for timing and so here again they are one of three choices that we could make so the first choice we could make is a synchronous system model and in a synchronous system model we assume that basically everything takes a known length of time so when we send a message over the network there is some maximum time after which the message will be either either delivered or lost but we assume that no message will take longer than some maximum amount of time to arrive also we're going to assume that nodes always execute their code at a known speed so every step of execution every step of the algorithm there's an upper bound for the length of time that that execution is going to take this is a very strong assumption now another assumption we could make is a partially synchronous model where for some periods of time the system behaves as in the synchronous model and for other periods of time it behaves in a way that's asynchronous and so i need to explain asynchronous so in an asynchronous model we make no timing assumptions at all so that means if you send a message over the network it may arrive in 20 years time okay we're not making any guarantees about how long it's going to take for messages to arrive we assume no upper bound on message latency of course it might be that messages are mostly delivered quite quickly but we're just not going to make any assumptions about the maximum latency that might occur moreover we're not going to make any assumptions about how fast nodes are going to execute the algorithm so we're going to assume that a nose node might pause its execution at any moment and just like stop executing its steps for a while and then later resume executing again and of course this can happen because a thread can be suspended as you know and so a thread can just pause execution for a while and then resume executing sometime later um and so we have here the synchronous model as one extreme where um where like we're making very strong assumptions about the network latency and the node processing speed and the asynchronous model where we're making no assumptions at all so the partially synchronous model is kind of a compromise between those two where we're saying that actually the asynchronous model is is great if we can work in the asynchronous model but there are certain problems that simply cannot be solved in the asynchronous model so in some cases we do have to make timing assumptions but at the same time it's unsafe to assume that those timing assumptions are always true because if you write an algorithm in the synchronous model and the system is ever asynchronous if this if the system ever takes longer than your upper bound to deliver a message for example then your algorithm might fail catastrophically so the algorithms are very very sensitive to your timing assumptions here and in most cases it is very dangerous to assume a synchronous model because real networks do in fact behave in partially synchronous ways so partially synchronous model is really our compromise where we're saying most of the time the system is well behaved and kind of synchronous and occasionally it just goes weird and occasionally messages take a really long time to arrive and occasionally nodes are really slow to execute and then at some point they'll return back into a synchronous state but we don't know whether they're asynchronous or synchronous right now so let me just explain the problems of assuming synchrony so you might think that you know usually networks are quite fast and usually you know if you send a message then it'll be arrived it'll arrive within some maximum time but unfortunately there are lots of reasons why why messages might take longer occasionally and so one reason might be that a message is lost and needs to be retried and so like we had earlier in our case of upgrading a fair loss link to a reliable link the cost of that upgrade in reliability was that potentially we have to wait for a very long time if there's a network partition we might have to wait for minutes or even hours or even days before the message gets through so in this case we can't assume any upper bound really on on message latency because it might be up to the length that it takes for our network partition to be healed. 

Other reasons why network latency might suddenly increase is just congestion and queuing in the network or there have even been examples of a network reconfiguration where packets just get stuck in a switch buffer for over a minute before they're eventually delivered and so even in in data center networks which are normally very well managed it is possible to actually occasionally have really extremely high message latency and so any algorithm that we design must take must take into account this possibility that occasionally messages might take a very long time to arrive in terms of the execution speed of nodes again we would expect normally like computers run at a kind of fixed speed you know flicks clock speed so we don't expect that to vary very much but there are many reasons why a node's execution might be interrupted for a little while so as you know from the concurrent systems part of this course, you can have a context switch you can have a thread that temporarily gets suspended while other processes run and so this might take a while before the operating system scheduler comes back and starts running your thread again, especially if there's some kind of problem going on like priority inversion in the system it could be that a process is actually paused for a significant amount of time before it gets to run again, and as you know from multi-threading a poor a process can or a thread can get paused that absolutely any moment there's you know any point in the code uh it could decide to to pause and so even at the most inconvenient place possible in an algorithm you might have a thread pause or a context switch.

Another real problem that happens in practice is garbage collection so in a language like java for example which performs automatic memory memory management and which uses garbage collection to free up memory, you can have what is called a stop the world garbage collection pause where the garbage collector just has to stop all of the running threads for a while while it performs the garbage collection and those pauses can last minutes sometimes, if you have a large threat large heap size so that again is another reason why a process or a thread might just pause execution for a while and uh finally of course there are lots of other things in the operating system that cause variable delays such as page faults, and so on especially if memory is tight. 

So it is possible to get around these things so real-time operating systems will provide scheduling guarantees they might guarantee that your code always runs runs at least once every 10 milliseconds but most distributed systems are not built on real-time operating systems they're built on general purpose operating systems which make no guarantees about how processes are going to get scheduled and even if you are using a real-time operating system it's very hard work to actually ensure that those timing guarantees always hold. 

So for most practical distributed systems we cannot assume any upper bound on how long it might take for both a message to be delivered or a process to execute one step, because you know, because these delays can occur unpredictably and non-deterministically at any point so that's a summary this is what we talked about system model contains consists of three parts there's we can make an assumption about the network how reliable we want the network, to be reliable fair loss or arbitrary, we make an assumption about how network how nodes are going to behave so are we going to assume crash stop where crash means a node never comes back or crash recovery or even byzantine behavior of nodes and then thirdly for the timing we can choose between synchronous or partially synchronous or asynchronous execution. 

These choices of abstraction are absolutely crucial so if you're designing a distributed algorithm you have to be absolutely certain that your assumption of in regard to these are correct so for example if you're assuming a crash recovery model and actually you have some byzantine nodes in your system the byzantine nodes are just going to destroy your algorithm so if you think they're going to be byzantine behavior then you have to take account for it in the algorithm and the algorithm has to be designed to tolerate byzantine behavior it is perfectly fine if you're going to assume this is a fully trusted system it's not going to have any byzantine nodes and just assume only crash stop or crash recovery that's fine you just have to be very sure that your assumption is correct likewise with timing making synchrony assumptions as i said assuming a asynchronous model when actually your system is partially synchronous is very dangerous it's very likely that if you assume a synchronous model and it goes partially synchronous even just for like 10 seconds somewhere the all of the guarantees of your distributed algorithm are off so you have to be very sure that your assumptions in terms of the synchrony model the node behavior and the network are correct.

# Fault Tolerance

In the last bit of this lecture i want to talk a little bit about a practical real-life context for faults handling faults and making highly available services so imagine you are running an online shop for example you probably want that shop to be available 24 hours a day seven days a week because who knows at what time of day or night somebody might decide that they want to go and look at your shop and maybe buy something and so any time during which your your shop your service is not available actually means losing money in other cases you might imagine that a service may even have contractual relationships with it with e with its customers specifying what percentage of time it a service needs to be available and so a typical model for how we usually talk about availability is the fraction of time during which a service is functioning correctly and so if a surface is functioning correctly 99 of the time for example that means that there might be three to four days a year during which the service is not available in total of course this might be several smaller outages or if you go up to 99.9 percent of the time you're allowed a maximum of nine hours per year of outage and you can increase this further to as many nines as you like, the telephone network for example is is apparently designed for five nines and so this is the the old-fashioned fixed-line telephone network, not mobile networks certainly not the internet they don't have this sort of availability uh the telephone network is designed in a very conservative way in order to achieve this this very high reliability but it is possible and typically terms that you get in the context of availability is slo and sla so an slo a service level objective is the goal that you are setting yourself in terms of the availability of a service

so this might specify the percentage of uh requests that need to get a correct response where the maximum time that it's allowed to take for that response, say 200 milliseconds or whatever and the period of time over which you're going to measure it so you're going to take that 99.9 percent over the course of all of the requests made in one day for example,

sla is basically a contract between a service and its customers or its consumers, specifying what the expected, service level is.

now in order to achieve that sort of very high availability, the way we typically do that is in distributed systems is by fault tolerance 

so a fault is when some part of the system isn't working we talked about node faults which might be a crash for example or network faults which might be a network partition and uh what we want is the system to tolerate some number of faults so it doesn't make sense to say that the top the system will tolerate all faults because if all of your nodes crash at the same time and all of your network links go down at the same time

the system is not going to be able to do anything obviously there's there's no way it can make any progress in that case 

but what you might be able to say is that the system as a whole will continue working if fewer than half of our nodes have crashed for example so you allow one out of three to crash or you allow two out of five to crash and the remaining nodes can still continue running the service, 

and so in a system in which some parts of the some nodes or some network links are allowed to be faulty uh we avoid what is called a single point of failure so a single point of failure would be say, one node that if that one node crashes then the system as a whole becomes unavailable 

but if we can design a system without a single point of failure that means that we can take out any one component of the system and the system as a whole will hopefully still continue working 

in order to enable to tolerate faults usually the first thing we have to do is to detect a fault and then we can handle it so the mechanism for detecting a fault is known as a failure detector terminology is a little bit odd it ought to actually be called should be called a fault detector that would make more sense but a failure detector is the the common term that is used so we're going to stick with that so a failure detector is it could be like a software algorithm or it could be a piece of hardware or something some mechanism for detecting whether another node is faulty and ideally what we would love to have is a perfect failure detector that is some mechanism that is always accurate at telling us whether another node is faulty or not 

now the way we typically implement failure detectors is we use timeouts so we simply send a message to a node and say hey please respond to this message if you're alive and then if we don't get a response within some amount of time then we say well okay we didn't get a response that node must be dead so it must have crashed or something like that 

and this is fine this is this is practical but unfortunately as we have seen in the context of our system models if we assume a partially synchronous or even an asynchronous system then a timeout doesn't necessarily tell us that the node has crashed because then timeout could also happen because we sent a message and the message was lost in the network or the response was lost in the network or the message was delayed in the network and it will actually still arrive it just hasn't arrived yet 

or the response was delayed in the network or maybe the node is actually alive but it's just experiencing a long garbage collection pause and so it will respond to your message in one minute's time once it's finished it's garbage collection, 

or of course the note might have crashed and it's impossible to tell the difference between any of these so it's impossible for the sender of of these these check messages to tell whether the absence of a response is due to a network problem 

or due to just some kind of random delay or due to problems because the node is actually crashed 

now the we can build a perfect failure detector if we have a synchronous system model and if we're going to assume only crash stop failures and certainly uh not going to assume any any byzantine behavior in the system

but you know as soon as you go to a partially synchronous model then timeouts are no longer an exact uh way of detecting failures so the best we can do in a partially synchronous system is what is called an eventually perfect failure detector i love this term you know nobody is perfect i like to think of myself as eventually perfect maybe you are also eventually perfect and then in the context of a failure detector eventually perfect means that the failure detector might be wrong from time to time so the failure detector might detect a timeout even though the other node hasn't actually crashed yet just because a message happened to be delayed a bit 

so it means a timeout does not accurately indicate that a crash has happened um also a failure detector is not immediate so if a crash has happened it might actually take a while until we detect that crash the detection of the crash is not instantaneous so we might be wrong we might have both false positives and false negatives for a while but eventually the failure detector labels a node as crashed if and only if it really has crashed so that means that any temporarily suspecting another node of being failed will will stop and we'll go back to thinking that a node is correct uh provided that the node really is still correct and also if a node has failed then eventually we will detect it as failed and so this is uh about the best we can do in terms of failure detection um but it's still quite useful so even though we might have uh this failure detector that is only eventually perfect this is actually sufficient in order to build some useful algorithms as we as we will see in some of the future lectures so that's all for today on system models.